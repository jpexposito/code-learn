<div align="justify">

# <img src=../../../images/coding-book.png width="40"> Code & Learn (Programaci√≥n de Servicios)

## Concurrencia

<div align="center">

<img src=images/concurrencia.png width="400">
</div>

Seg√∫n el diccionario de la __RAEA__ brir en una ventana nueva una de las acepciones de concurrencia es

>üí° Coincidencia, concurso simult√°neo de varias circunstancias.

___Si cambiamos circunstancias por procesos, ya tendr√≠amos una definici√≥n cercana a lo que significa concurrencia en el mundo digital.___

Si nos fijamos, no es la primera vez que surge la palabra proceso en este texto, y ___es que los procesos son una pieza fundamental del puzle, por no decir la parte m√°s importante___.

### Concurrencia vs Paralelismo

Ahora que ya sabemos qu√© es un proceso, vamos a ver la relaci√≥n que √©stos tienen con el hardware en el que se ejecutan.

#### Monoproceso

Por mucho que tengamos varios procesos procesos ejecut√°ndose a la vez, si s√≥lo tenemos un microprocesador para atenderlos a todos, estas tareas nunca van a poder ejecutarse a la vez.

Una posibilidad ser√≠a la ejecuci√≥n secuencias de las tareas en el sistema. Se empieza a ejecutar una tarea y, hasta que esta no finaliza, el sistema no empieza a ejecutar la siguiente. Esto se corresponder√≠a con sistemas que s√≥lo son capaces de hacer una tarea a la vez, algo raro hoy en d√≠a.

<div align="center">

<img src=images/proceso-1.svg width="400">
</div>

### Multiprogramaci√≥n

Para que los procesos no tengan que esperar a que todos los dem√°s se ejecuten, los sistemas aprovechan y exprimen los recursos al m√°ximo, permitiendo la ilusi√≥n de que varios procesos se ejecutan de forma simult√°nea. Esto es lo que se conoce como multitarea.

En estos sistemas, se aprovecha el dise√±o de los sistemas operativos modernos, y de las operaciones que realizan los procesos que no requieren el uso del procesador (esperar a una operaci√≥n de E/S, una interacci√≥n con el usuario, la recepci√≥n de informaci√≥n desde la red, etc.) para poder ejecutar otros procesos. La ejecuci√≥n se multiplexa en el tiempo.

<div align="center">

<img src=images/proceso-2.svg width="400">
</div>

Como se puede observar en las dos im√°genes anteriores (aunque se trata s√≥lo de un modelo), el tiempo de uso total del procesador es igual en ambos casos, es decir, que el sistema tardar√° el mismo tiempo en completar todas las tareas. Sin embargo, la sensaci√≥n es que todas las tareas se est√°n realizando a la vez.

### Paralelismo

Con el avance de la tecnolog√≠a ahora la gran mayor√≠a de dispositivos, desde los equipos de escritorio, port√°tiles, dispositivos m√≥viles, ... hasta los dispositivos IoT, tienen capacidades de multiproceso, es decir, tienen m√°s de un procesador para poder realizar varias tareas a la vez de forma real, no simulada. A este tipo de ejecuci√≥n es a lo que llamamos paralelismo.

<div align="center">

<img src=images/proceso-3.svg width="400">
</div>

En este caso, a mayor n√∫mero de unidades de proceso, menor tiempo tardar√°n las tareas en completarse y mayor ser√° la sensaci√≥n de rapidez que notar√° el usuario. Este es uno de los retos de los sistemas operativos, planificar adecuadamente las tareas para minimizar los tiempos de ejecuci√≥n, de espera y el uso de los recursos del sistema, el procesador principalmente.

>üí° n√∫cleos vs hilos
>
> Si hab√©is comprado un procesador hace poco, o est√°is al d√≠a en cuanto al hardware, sabr√©is que una de las caracter√≠sticas de los procesadores es su n√∫mero de n√∫cleos (4, 8, 16).
>
>Pero adem√°s, al n√∫mero de n√∫cleos lo acompa√±a otra caracter√≠stica que es el n√∫mero de hilos o threads, que suele ser el doble que el de n√∫cleos.
>
>¬øQu√© implicaci√≥n tienen los threads de un procesador con respecto a la concurrencia? ¬øSi un equipo tiene 8 n√∫cleos / 16 hilos significa eso que puede ejecutar 16 procesos a la vez?

#### Sistemas distribuidos

>üìå "Un sistema distribuido es una colecci√≥n de computadores independientes que aparecen ante los usuarios como un √∫nico sistema coherente"
>
>___"Andrew S. Tanembaum"___

Posiblemente el ejemplo m√°s famoso y conocido de sistema distribuido sea Internet.Internet aparece ante los usuarios como un enorme repositorio de documentos, es decir, como un √∫nico sistema capaz de proveer casi cualquier tipo de informaci√≥n o servicio que se necesite. No obstante, sabemos que est√° compuesta por millones de equipos ubicados en localizaciones diferentes e interconectados entre s√≠.

Nace de la necesidad de compartir recursos. Actualmente el m√°ximo exponente de este tipo de sistemas es el Cloud Computing o servicios en la nube. Un sistema es distribuido cuando los componentes software est√°n distribuidos en la red, se comunican y coordinan mediante el paso de mensajes.

Las caracter√≠sticas de este tipo de sistemas son::

- Concurrencia: ejecuci√≥n de programas concurrentes.
- Inexistencia de un reloj global. - Implica sincronizarse con el paso de mensajes.
- Fallos independientes: cada componente del sistema puede fallar sin que perjudique la ejecuci√≥n de los dem√°s.

#### Ventajas e inconvenientes

Ventajas del procesamiento paralelo:

- Ejecuci√≥n simult√°nea de tareas.
- Disminuye el tiempo total de ejecuci√≥n
- Resuelve problemas complejos y de grandes dimensiones.
- Utilizaci√≥n de recursos no locales distribuidos en la red
- Disminuci√≥n de costos, aprevechando los recursos distribuidos, no es necesario gastar en un √∫nico supercomputardor, se puede alcanzar el mismo poder de computaci√≥n con equipos m√°s modestos distribuidos.
Inconvenientes del procesamiento paralelo:

Los compiladores y entornos de programaci√≥n para sistemas paralelos son m√°s complicados de desarrollar.
Los programas paralelos son m√°s dif√≠ciles de escribir
Hay mayor consumo de energ√≠a
Mayor complejidad en el acceso a datos
Complejidad a la hora de la comunicaci√≥n y sincronizaci√≥n de las diferentes subtareas. cuidado
Ventajas de la programaci√≥n distribuida

Se comparten recursos y datos
Crecimiento bajo demanda
Mayor flexibildad para distribuir la carga
Alta disponibilidad
Soporte de aplicaciones distribuidas
Filosof√≠a abierta y hetereog√©nea
Escalado de sistemas

Con escalado nos referimos a la posibilidad de incrementar las capacidades de un sistema.

Investiga las diferencias, ventajas e inconvenientes del escalado horizontal y el escalado vertical.

Inconvenientes de la programaci√≥n distribuida

- Aumenta la complejidad
- Se necesita software nuevo especializado
- Problemas derivados de las comunicaciones (perdidas, saturaciones, etc.)
- Problemas de seguridad, ataques DDoS
- Ejemplos de utilizaci√≥n de la programaci√≥n paralela y distribuida

  - Estudios meteorol√≥gicos
  - Estudios del genoma humano
  - Modelado de la biosfera
  - Predicciones s√≠smicas
  - Simulaci√≥n de mol√©culas
  - Ejemplo de programaci√≥n paralela y distribuida

>‚ùó B√∫squeda de inteligencia extraterrestre - Proyecto SETI

### Condiciones de Bernstein

Una vez que sabemos qu√© es un programa concurrente y las distintas arquitecturas hardware que pueden soportarlo, vamos a ver qu√© partes de un programa se pueden ejecutar de forma concurrente y cu√°les no.

Si observamos el siguiente c√≥digo, queda claro que la primera instrucci√≥n se debe ejecutar antes que la segunda para que el resultado sea siempre el mismo (para los mismos datos de entrada).

```java
x = x + 1;
y = x + 1;
```

Sin embargo, en un c√≥digo como el siguiente el √≥rden en el que se ejecuten las instrucciones no influye en el resultado final (valor de las variables). En este caso se pueden ejecutar las tres sentencias a la vez incrementando la velocidad de procesamiento.

```java
x = 1;
y = 2;
z = 3;
```

>üí° A.J. Bernstein defini√≥ unas condiciones para determinar si dos conjuntos de instrucciones Si y Sj se pueden ejecutar concurrentemente.

Para poder determinar si dos conjuntos de instrucciones se pueden ejecutar concurrentemente, se definen en primer lugar los siguientes conjuntos

- L(Sk) = {a1, a2, a3, ...} como el conjunto de lectura formado por todas las variables cuyos valores se leen durante la ejecuci√≥n de las instrucciones del conjunto k.
- E(Sk) = {b1, b2, b3, ...} como el conjunto de escritura formado por todas las variables cuyos valores se actualizan durante la ejecuci√≥n de las instrucciones del conjunto k.
Para que dos conjuntos de instrucciones Si y Sj se puedan ejecutar concurrentemente, se deben cumplir estas tres condiciones de forma simult√°nea.

- L(Si) ‚à© E(Sj)
- E(Si) ‚à© L(Sj)
- E(Si) ‚à© E(Sj)
Cuales de estas instrucciones se pueden ejecutar de forma concurrente

```java
a = x + y;
b = z - 1;
c = a - b;
w = c + 1;
```

Primero deber√≠amos obtener los conjuntos L y E para cada sentencia

- L(S1) = {x, y}

- E(S1) = {a}

- L(S2) = {z}

- E(S2) = {b}

- L(S3) = {a, b}

- E(S3) = {c}

- L(S4) = {c}

- E(S4) = {w}

Y ahora aplicarlas entre cada par de sentencias

- L(S1) ‚à© E(S2) = ‚àÖ
- E(S1) ‚à© L(S2) = ‚àÖ 
- E(S1) ‚à© E(S2) = ‚àÖ 

> S√≠ se pueden ejecutar concurrentemente

- L(S1) ‚à© E(S3) = ‚àÖ
- E(S1) ‚à© L(S3) = {a} ‚â† ‚àÖ 
- E(S1) ‚à© E(S3) = ‚àÖ // 
- > NO se pueden ejecutar concurrentemente

- L(S1) ‚à© E(S4) = ‚àÖ
- E(S1) ‚à© L(S4) = ‚àÖ
- E(S1) ‚à© E(S4) = ‚àÖ

> S√≠ se pueden ejecutar concurrentemente

- L(S2) ‚à© E(S3) = ‚àÖ
-  E(S2) ‚à© L(S3) = {b] ‚â† E(S2) ‚à© E(S3) = ‚àÖ

> NO se pueden ejecutar concurrentemente

- L(S2) ‚à© E(S4) = ‚àÖ
- E(S2) ‚à© L(S4) = ‚àÖ
- E(S2) ‚à© E(S4) = ‚àÖ

>S√≠ se pueden ejecutar concurrentemente

- L(S3) ‚à© E(S4) = ‚àÖ
- E(S3) ‚à© L(S4) = {c} ‚â† ‚àÖ E(S3) ‚à© E(S4) = ‚àÖ
> NO se pueden ejecutar concurrentemente

[Procesos-so](PROCESOS-SO.md)

## Licencia üìÑ

Este proyecto est√° bajo la Licencia (Apache 2.0) - mira el archivo [LICENSE.md](../../../LICENSE) para detalles

</div>